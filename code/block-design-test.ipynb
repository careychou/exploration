{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as tfd\n",
    "\n",
    "import edward as ed\n",
    "from edward.models import Normal\n",
    "from edward.models import MultivariateNormalFullCovariance\n",
    "from edward.models import MultivariateNormalTriL\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../doc/tc_fda.csv')\n",
    "data = data.drop_duplicates()\n",
    "data['sales'] = data['cont_sales'] + data['test_sales_post_contact']\n",
    "data = data.join(pd.get_dummies(data['row_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pd_train = data.iloc[:, -2:]\n",
    "y_pd_train = data.loc[:, ['sales']]\n",
    "y_pd_train = np.log(y_pd_train + 1)\n",
    "\n",
    "x_train = x_pd_train.as_matrix()\n",
    "y_train = np.squeeze(y_pd_train.as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>fixed effect model - assume store is not from the sample design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [100%] ██████████████████████████████ Elapsed: 10s | Loss: 3199.923\n"
     ]
    }
   ],
   "source": [
    "sess = ed.get_session()\n",
    "\n",
    "N, D = x_train.shape\n",
    "fixed_effects = tf.placeholder(tf.float32, [N, D])\n",
    "\n",
    "beta_fixed_effects = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "alpha = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "# simple fxied effect model\n",
    "mu_y = alpha + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# latent fixed effects\n",
    "q_beta_fixed_effects = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([D])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    ")\n",
    "q_alpha = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([1])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([1])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, y: y_train})\n",
    "inference.run(n_samples=20, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>cont</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.60844</td>\n",
       "      <td>0.832406</td>\n",
       "      <td>0.863445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha      cont      test\n",
       "0  0.60844  0.832406  0.863445"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lift: 0.03594785928726196'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fixed effect estimate\n",
    "q_beta_approx = np.mean(q_beta_fixed_effects.sample(500).eval(), axis=0)\n",
    "q_alpha_approx = np.mean(q_alpha.sample(500).eval(), axis=0)\n",
    "\n",
    "df = [pd.DataFrame({x_pd_train.columns.values[i]:q_beta_approx[i]}, index=[0]) for i in range(2)]\n",
    "display(pd.DataFrame(q_alpha_approx, columns=['alpha']).join(df))\n",
    "display('lift: ' + str((1 - q_beta_approx[0]/q_beta_approx[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 2.3183417\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_absolute_error(y_posterior, X_val_feed_dict, y_val):\n",
    "    data = {y_posterior: y_val}\n",
    "    data.update(X_val_feed_dict)\n",
    "    mae = ed.evaluate('mean_absolute_error', data=data)\n",
    "    return mae\n",
    "    \n",
    "def plot_residuals(y_posterior, X_val_feed_dict, title, y_val):\n",
    "    y_posterior_preds = y_posterior.eval(feed_dict=X_val_feed_dict)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.hist(y_posterior_preds - y_val, edgecolor='white', linewidth=1, bins=30, alpha=.7)\n",
    "    plt.axvline(0, color='#A60628', linestyle='--')\n",
    "    plt.xlabel('`y_posterior_preds - y_val`', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "\n",
    "X_feed_dict = {\n",
    "  fixed_effects: x_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>mixed effect - equal store covariance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [0.8262286 0.8262286 0.8262286 0.8262286 0.8262286 0.8262286 0.8262286\n",
      " 0.8262286 0.8262286 0.8262286 0.8262286 0.8262286 0.8262286 0.8262286\n",
      " 0.8262286]\n",
      "500/500 [100%] ██████████████████████████████ Elapsed: 13s | Loss: 3120.764\n"
     ]
    }
   ],
   "source": [
    "store_train = pd.Categorical(data.Store).codes + 1\n",
    "n_store = len(set(store_train))\n",
    "\n",
    "# random-effect placeholder\n",
    "store_data = tf.placeholder(tf.int32, [N])\n",
    "\n",
    "# random-effect parameter : assume equal covariance structure in store\n",
    "sigma_store = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([])))) * tf.ones(n_store)\n",
    "alpha_store = Normal(loc=tf.zeros(n_store), scale=sigma_store)\n",
    "    \n",
    "# random effect model\n",
    "alpha_random_effects = tf.gather(alpha_store, store_data)\n",
    "mu_y = alpha + alpha_random_effects + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_store = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_store])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_store])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha,\n",
    "    alpha_store: q_alpha_store\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(sigma_store)) # G\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, store_data: store_train, y: y_train})\n",
    "inference.run(n_samples=20, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>cont</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4637</td>\n",
       "      <td>1.286143</td>\n",
       "      <td>1.34775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha      cont     test\n",
       "0  0.4637  1.286143  1.34775"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lift: 0.04571110010147095'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fixed effect estimate\n",
    "q_beta_approx = np.mean(q_beta_fixed_effects.sample(500).eval(), axis=0)\n",
    "q_alpha_approx = np.mean(q_alpha.sample(500).eval(), axis=0)\n",
    "\n",
    "df = [pd.DataFrame({x_pd_train.columns.values[i]:q_beta_approx[i]}, index=[0]) for i in range(2)]\n",
    "display(pd.DataFrame(q_alpha_approx, columns=['alpha']).join(df))\n",
    "display('lift: ' + str((1 - q_beta_approx[0]/q_beta_approx[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_code</th>\n",
       "      <th>Z</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.265160</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.180868</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.584251</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.417737</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.246331</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.550649</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.085242</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.432471</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.621422</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.805410</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.056613</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.880643</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.783839</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store_code         Z         G\n",
       "0            1  0.030680  0.866025\n",
       "1            2 -0.265160  0.866025\n",
       "2            3  0.180868  0.866025\n",
       "3            4 -0.584251  0.866025\n",
       "4            5  0.417737  0.866025\n",
       "5            6 -1.246331  0.866025\n",
       "6            7 -0.550649  0.866025\n",
       "7            8 -1.085242  0.866025\n",
       "8            9 -0.432471  0.866025\n",
       "9           10 -0.621422  0.866025\n",
       "10          11 -0.805410  0.866025\n",
       "11          12 -0.056613  0.866025\n",
       "12          13  1.880643  0.866025\n",
       "13          14  0.739874  0.866025\n",
       "14          15 -0.783839  0.866025"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randon effect Z and G estimate\n",
    "q_alpha_store_approx = np.mean(q_alpha_store.sample(500).eval(), axis=0)\n",
    "G = sess.run(sigma_store)\n",
    "\n",
    "data['store_code'] = pd.Categorical(data.Store).codes + 1\n",
    "Gdata = data.loc[:, ['Store', 'store_code']].drop_duplicates().sort_values('store_code').reset_index(drop=True)\n",
    "Z_df = pd.DataFrame(q_alpha_store_approx, columns=['Z'])\n",
    "G_df = pd.DataFrame(G, columns=['G'])\n",
    "Gdata.join(Z_df).join(G_df).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 2.2102077\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    store_data: store_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> mixed effect - unequal store covariance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [0.8720654  1.5931737  0.82884234 0.5776716  1.0093937  0.8402702\n",
      " 1.3447489  0.6262644  0.97905767 0.55013746 1.5606128  0.68117565\n",
      " 0.8256269  1.2945778  0.5599462 ]\n",
      "500/500 [100%] ██████████████████████████████ Elapsed: 42s | Loss: 3114.836\n"
     ]
    }
   ],
   "source": [
    "# n_store x n_store diag cov matrix\n",
    "sigma_store_cov = tf.diag(tf.sqrt(tf.exp(tf.Variable(tf.random_normal([n_store])))))\n",
    "alpha_store = MultivariateNormalFullCovariance(loc=tf.zeros(n_store), covariance_matrix=sigma_store_cov)\n",
    "\n",
    "# approximate random-effect distribution\n",
    "alpha_random_effects = tf.gather(alpha_store, store_data)\n",
    "mu_y = alpha + alpha_random_effects + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_store = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_store])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_store])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha,\n",
    "    alpha_store: q_alpha_store\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(tf.diag_part(sigma_store_cov))) # G\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, store_data: store_train, y: y_train})\n",
    "inference.run(n_samples=20, n_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>cont</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.698813</td>\n",
       "      <td>0.60942</td>\n",
       "      <td>0.671946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha     cont      test\n",
       "0  0.698813  0.60942  0.671946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'lift: 0.09305208921432495'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fixed effect estimate\n",
    "q_beta_approx = np.mean(q_beta_fixed_effects.sample(500).eval(), axis=0)\n",
    "q_alpha_approx = np.mean(q_alpha.sample(500).eval(), axis=0)\n",
    "\n",
    "df = [pd.DataFrame({x_pd_train.columns.values[i]:q_beta_approx[i]}, index=[0]) for i in range(2)]\n",
    "display(pd.DataFrame(q_alpha_approx, columns=['alpha']).join(df))\n",
    "display('lift: ' + str((1 - q_beta_approx[0]/q_beta_approx[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_code</th>\n",
       "      <th>Z</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.029793</td>\n",
       "      <td>2.385794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.081055</td>\n",
       "      <td>0.012081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.570032</td>\n",
       "      <td>0.357328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.036850</td>\n",
       "      <td>0.004951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.842657</td>\n",
       "      <td>0.744312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.805648</td>\n",
       "      <td>0.691579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.067491</td>\n",
       "      <td>0.021327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.674050</td>\n",
       "      <td>0.480821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.015424</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>0.008834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.340587</td>\n",
       "      <td>0.125688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.315934</td>\n",
       "      <td>0.128637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>2.780230</td>\n",
       "      <td>7.439398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.147851</td>\n",
       "      <td>1.570163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.455350</td>\n",
       "      <td>0.695428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store_code         Z         G\n",
       "0            1 -0.029793  2.385794\n",
       "1            2  0.081055  0.012081\n",
       "2            3  0.570032  0.357328\n",
       "3            4 -0.036850  0.004951\n",
       "4            5  0.842657  0.744312\n",
       "5            6 -0.805648  0.691579\n",
       "6            7 -0.067491  0.021327\n",
       "7            8 -0.674050  0.480821\n",
       "8            9 -0.015424  0.001727\n",
       "9           10 -0.033980  0.008834\n",
       "10          11 -0.340587  0.125688\n",
       "11          12  0.315934  0.128637\n",
       "12          13  2.780230  7.439398\n",
       "13          14  1.147851  1.570163\n",
       "14          15 -0.455350  0.695428"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randon effect Z and G estimate\n",
    "q_alpha_store_approx = np.mean(q_alpha_store.sample(500).eval(), axis=0)\n",
    "G =  sess.run(tf.diag_part(sigma_store_cov))\n",
    "\n",
    "data['store_code'] = pd.Categorical(data.Store).codes + 1\n",
    "Gdata = data.loc[:, ['Store', 'store_code']].drop_duplicates().sort_values('store_code').reset_index(drop=True)\n",
    "Z_df = pd.DataFrame(q_alpha_store_approx, columns=['Z'])\n",
    "G_df = pd.DataFrame(G, columns=['G'])\n",
    "Gdata.join(Z_df).join(G_df).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 2.2140877\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    store_data: store_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
