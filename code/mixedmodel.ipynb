{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as tfd\n",
    "\n",
    "import edward as ed\n",
    "from edward.models import Normal\n",
    "from edward.models import MultivariateNormalFullCovariance\n",
    "from edward.models import MultivariateNormalTriL\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import csv\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>students</th>\n",
       "      <th>instructors</th>\n",
       "      <th>studage</th>\n",
       "      <th>lectage</th>\n",
       "      <th>service</th>\n",
       "      <th>departments</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39262</th>\n",
       "      <td>1597</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58553</th>\n",
       "      <td>2366</td>\n",
       "      <td>761</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>378</td>\n",
       "      <td>558</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41694</th>\n",
       "      <td>1692</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>44</td>\n",
       "      <td>1085</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       students  instructors  studage  lectage  service  departments  ratings\n",
       "39262      1597           23        8        2        0            1        3\n",
       "58553      2366          761        6        2        0            9        4\n",
       "10062       378          558        2        1        1            1        3\n",
       "41694      1692         1008        2        6        1            5        5\n",
       "849          44         1085        6        6        1            5        4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_insteval():  \n",
    "  url = ('https://raw.github.com/vincentarelbundock/Rdatasets/master/csv/'\n",
    "         'lme4/InstEval.csv')\n",
    "  with requests.Session() as s:\n",
    "    download = s.get(url)\n",
    "    f = download.content.decode().splitlines()\n",
    "\n",
    "  iterator = csv.reader(f)\n",
    "  columns = next(iterator)[1:]\n",
    "  x_train = np.array([row[1:] for row in iterator], dtype=np.int)\n",
    "  metadata = {'columns': columns}\n",
    "  return x_train, metadata\n",
    "\n",
    "data, metadata = load_insteval()\n",
    "data = pd.DataFrame(data, columns=metadata['columns'])\n",
    "data = data.rename(columns={'s': 'students',\n",
    "                            'd': 'instructors',\n",
    "                            'dept': 'departments',\n",
    "                            'y': 'ratings'})\n",
    "data['students'] -= 1  # start index by 0\n",
    "# Remap categories to start from 0 and end at max(category).\n",
    "data['instructors'] = data['instructors'].astype('category').cat.codes\n",
    "data['departments'] = data['departments'].astype('category').cat.codes\n",
    "\n",
    "train = data.sample(frac=0.8)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       studage  service  lectage\n",
      "39262        8        0        2\n",
      "58553        6        0        2\n",
      "10062        2        1        1\n",
      "41694        2        1        6\n",
      "849          6        1        6\n",
      "(58737, 3)\n",
      "(58737, 1)\n"
     ]
    }
   ],
   "source": [
    "x_pd_train = train.loc[:, ['studage', 'service', 'lectage']]\n",
    "y_pd_train = train.loc[:, ['ratings']]\n",
    "\n",
    "print(x_pd_train.head())\n",
    "print(x_pd_train.shape)\n",
    "print(y_pd_train.shape)\n",
    "\n",
    "x_train = x_pd_train.as_matrix()\n",
    "y_train = np.squeeze(y_pd_train.as_matrix())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>fixed effect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [100%] ██████████████████████████████ Elapsed: 4s | Loss: 117224.297\n"
     ]
    }
   ],
   "source": [
    "sess = ed.get_session()\n",
    "\n",
    "N, D = x_train.shape\n",
    "fixed_effects = tf.placeholder(tf.float32, [N, D])\n",
    "\n",
    "beta_fixed_effects = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "alpha = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "# simple fxied effect model\n",
    "mu_y = alpha + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# latent fixed effects\n",
    "q_beta_fixed_effects = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([D])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([D])))\n",
    ")\n",
    "q_alpha = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([1])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([1])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studage' 'service' 'lectage']\n",
      "[array([2.622828], dtype=float32), array([-0.02773242,  0.04706466,  0.06124683], dtype=float32)]\n",
      "[2.7247205]\n",
      "[array([2.622828], dtype=float32), array([-0.02773242,  0.04706466,  0.06124683], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_absolute_error(y_posterior, X_val_feed_dict, y_val):\n",
    "    data = {y_posterior: y_val}\n",
    "    data.update(X_val_feed_dict)\n",
    "    mae = ed.evaluate('mean_absolute_error', data=data)\n",
    "    return mae\n",
    "    \n",
    "def plot_residuals(y_posterior, X_val_feed_dict, title, y_val):\n",
    "    y_posterior_preds = y_posterior.eval(feed_dict=X_val_feed_dict)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.hist(y_posterior_preds - y_val, edgecolor='white', linewidth=1, bins=30, alpha=.7)\n",
    "    plt.axvline(0, color='#A60628', linestyle='--')\n",
    "    plt.xlabel('`y_posterior_preds - y_val`', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "\n",
    "# fixed effect estimate\n",
    "q_beta_approx = sess.run(q_beta_fixed_effects)\n",
    "q_alpha_approx = sess.run(q_alpha)\n",
    "\n",
    "print(x_pd_train.columns.values)\n",
    "print(q_beta_approx)\n",
    "print(q_alpha_approx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.170808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_feed_dict = {\n",
    "  fixed_effects: x_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>random effect model - equal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [100%] ██████████████████████████████ Elapsed: 2s | Loss: 106241.289\n"
     ]
    }
   ],
   "source": [
    "dep_pd_train = train.loc[:, ['departments']]\n",
    "dep_train = np.squeeze(dep_pd_train.as_matrix())\n",
    "\n",
    "\n",
    "n_dep = len(set(dep_train))\n",
    "\n",
    "# random-effect placeholder\n",
    "dep_data = tf.placeholder(tf.int32, [N])\n",
    "\n",
    "# random-effect parameter : assume equal covariance structure in dep\n",
    "sigma_dep = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([])))) * tf.ones(n_dep)\n",
    "alpha_dep = Normal(loc=tf.zeros(n_dep), scale=sigma_dep)\n",
    "    \n",
    "# random effect model\n",
    "alpha_random_effects = tf.gather(alpha_dep, dep_data)\n",
    "mu_y = alpha_random_effects \n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_dep = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_dep])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_dep])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    alpha_dep: q_alpha_dep\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "inference = ed.KLqp(latent_vars, data={dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zmu= [3.2616158 3.034792  3.2538793 3.2376688 3.3177757 3.1352441 3.1963053\n",
      " 3.3461442 3.2476082 2.9905765 3.048823  3.3217654 3.140234  3.4214945]\n",
      "G= [3.2198095 3.2198095 3.2198095 3.2198095 3.2198095 3.2198095 3.2198095\n",
      " 3.2198095 3.2198095 3.2198095 3.2198095 3.2198095 3.2198095 3.2198095]\n"
     ]
    }
   ],
   "source": [
    "q_alpha_dep_approx = sess.run(q_alpha_dep)\n",
    "alpha_dep_approx = sess.run(alpha_dep)\n",
    "\n",
    "# Z estimate of random effect without fixed effect\n",
    "print('Zmu=', q_alpha_dep_approx)\n",
    "print('G=', sess.run(sigma_dep)) # G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.1272258\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "  dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> random effect model - heterogeneous variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [[1.029081   0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.8264735  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.39852992 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.5416019  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         1.0534979  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.3505843\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  2.079865   0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.46322328 0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.7953596  0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.55965185 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.570708   0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.9516677\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.6545602  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.1641302 ]]\n",
      "250/250 [100%] ██████████████████████████████ Elapsed: 6s | Loss: 105950.242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# n_dep x n_dep diag cov matrix\n",
    "sigma_dep_cov = tf.diag(tf.sqrt(tf.exp(tf.Variable(tf.random_normal([n_dep])))))\n",
    "alpha_dep = MultivariateNormalFullCovariance(loc=tf.zeros(n_dep), covariance_matrix=sigma_dep_cov)\n",
    "\n",
    "alpha_random_effects = tf.gather(alpha_dep, dep_data)\n",
    "mu_y = alpha_random_effects \n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_dep = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_dep])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_dep])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    alpha_dep: q_alpha_dep\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(sigma_dep_cov)) # G\n",
    "inference = ed.KLqp(latent_vars, data={dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zmu= [3.3674629 2.9415636 3.2403724 3.2213168 3.3243597 3.1481068 3.2820544\n",
      " 3.0075145 3.1041389 2.9472804 3.0868754 3.330988  3.1402197 3.229673 ]\n",
      "G= [[10.774364  0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        9.732782  0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.       11.051674  0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.       10.035205  0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.       11.324817  0.        0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        9.647827  0.\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.       10.51235\n",
      "   0.        0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "  10.175135  0.        0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.       10.040149  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        9.040032  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        9.302696  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.       10.98457   0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        9.716397  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.        0.\n",
      "   0.        0.        0.        0.        0.        0.       10.666109]]\n"
     ]
    }
   ],
   "source": [
    "q_alpha_dep_approx = sess.run(q_alpha_dep)\n",
    "alpha_dep_approx = sess.run(alpha_dep)\n",
    "\n",
    "# Z estimate of random effect without fixed effect\n",
    "print('Zmu=', q_alpha_dep_approx)\n",
    "print('G=', sess.run(sigma_dep_cov)) # G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.1289918\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "  dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>mixed effect - one random effect (dep) equal variance with other covariates fixed effect</h1>\n",
    "equal variance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [0.97989684 0.97989684 0.97989684 0.97989684 0.97989684 0.97989684\n",
      " 0.97989684 0.97989684 0.97989684 0.97989684 0.97989684 0.97989684\n",
      " 0.97989684 0.97989684]\n",
      "250/250 [100%] ██████████████████████████████ Elapsed: 5s | Loss: 121358.398\n"
     ]
    }
   ],
   "source": [
    "# random-effect parameter : assume equal covariance structure in dep\n",
    "sigma_dep = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([])))) * tf.ones(n_dep)\n",
    "alpha_dep = Normal(loc=tf.zeros(n_dep), scale=sigma_dep)\n",
    "\n",
    "mu_y = alpha + alpha_random_effects + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha,\n",
    "    alpha_dep: q_alpha_dep\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(sigma_dep)) # G\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studage' 'service' 'lectage']\n",
      "[ 0.05875277  0.11151692 -0.08240282]\n",
      "[2.8785944]\n",
      "Zmu= [-1.5300514   0.14231429 -0.2920328   0.21554333 -0.43503466 -0.03421251\n",
      " -0.34855068  0.36965793  0.66997194  0.81366336  0.19649018  0.25965518\n",
      "  0.30878806 -0.12333563]\n",
      "G= [0.6721047 0.6721047 0.6721047 0.6721047 0.6721047 0.6721047 0.6721047\n",
      " 0.6721047 0.6721047 0.6721047 0.6721047 0.6721047 0.6721047 0.6721047]\n"
     ]
    }
   ],
   "source": [
    "# fixed effect estimate\n",
    "q_beta_approx = sess.run(q_beta_fixed_effects)\n",
    "q_alpha_approx = sess.run(q_alpha)\n",
    "\n",
    "print(x_pd_train.columns.values)\n",
    "print(q_beta_approx)\n",
    "print(q_alpha_approx)\n",
    "\n",
    "q_alpha_dep_approx = sess.run(q_alpha_dep)\n",
    "\n",
    "# Z estimate of random effect without fixed effect\n",
    "print('Zmu=', q_alpha_dep_approx)\n",
    "print('G=', sess.run(sigma_dep)) # G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.1350775\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> mixed effect with unstructured covariance model</h1>\n",
    "in this model every pair of dep has its own unique correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [[ 1.4661205   1.2567146   0.44513345  2.0980053   1.2986672   0.73544854\n",
      "   0.84401715  0.96918815  1.422813    1.2204816   0.6516401   1.5926483\n",
      "   0.62585634  1.055317  ]\n",
      " [ 1.2567146   1.7324431   1.6622988   3.2350748   2.0865853   1.4187217\n",
      "   1.8728228   2.8125167   1.8205144   1.5505215   2.1090965   1.9787192\n",
      "   2.2865708   1.9182717 ]\n",
      " [ 0.44513345  1.6622988   5.3640375   5.0454326   4.172286    2.659605\n",
      "   4.8638096   6.8465652   5.721972    4.0967474   6.9263983   2.5839782\n",
      "   4.8969765   4.208788  ]\n",
      " [ 2.0980053   3.2350748   5.0454326  13.784096    8.878807   10.986081\n",
      "   7.8173375   9.909452    9.635937    6.7604837   7.817145    5.6738844\n",
      "   6.8227463   8.332856  ]\n",
      " [ 1.2986672   2.0865853   4.172286    8.878807    6.7826943   7.0757318\n",
      "   6.4946194   8.5500965   7.7550592   6.9959254   7.3082623   4.576431\n",
      "   7.3657074   7.3113403 ]\n",
      " [ 0.73544854  1.4187217   2.659605   10.986081    7.0757318  10.812378\n",
      "   6.535928    7.6949377   7.7771354   5.9966345   5.8586307   4.385204\n",
      "   6.5596      7.504895  ]\n",
      " [ 0.84401715  1.8728228   4.8638096   7.8173375   6.4946194   6.535928\n",
      "   9.26651    11.235602    8.961255   10.624655   10.251934    6.1084223\n",
      "  12.988365    9.460968  ]\n",
      " [ 0.96918815  2.8125167   6.8465652   9.909452    8.5500965   7.6949377\n",
      "  11.235602   17.604908   11.296046   13.783411   15.06307     8.4746275\n",
      "  17.097712   12.74325   ]\n",
      " [ 1.422813    1.8205144   5.721972    9.635937    7.7550592   7.7771354\n",
      "   8.961255   11.296046   12.167748   11.687043   11.935519    6.876256\n",
      "   9.910795   10.554112  ]\n",
      " [ 1.2204816   1.5505215   4.0967474   6.7604837   6.9959254   5.9966345\n",
      "  10.624655   13.783411   11.687043   21.141947   16.414112   11.381618\n",
      "  19.721497   15.917412  ]\n",
      " [ 0.6516401   2.1090965   6.9263983   7.817145    7.3082623   5.8586307\n",
      "  10.251934   15.06307    11.935519   16.414112   19.524866   12.764114\n",
      "  17.37473    14.9332905 ]\n",
      " [ 1.5926483   1.9787192   2.5839782   5.6738844   4.576431    4.385204\n",
      "   6.1084223   8.4746275   6.876256   11.381618   12.764114   14.351183\n",
      "  13.349209   12.281011  ]\n",
      " [ 0.62585634  2.2865708   4.8969765   6.8227463   7.3657074   6.5596\n",
      "  12.988365   17.097712    9.910795   19.721497   17.37473    13.349209\n",
      "  26.85183    18.110104  ]\n",
      " [ 1.055317    1.9182717   4.208788    8.332856    7.3113403   7.504895\n",
      "   9.460968   12.74325    10.554112   15.917412   14.9332905  12.281011\n",
      "  18.110104   22.803684  ]]\n",
      "250/250 [100%] ██████████████████████████████ Elapsed: 8s | Loss: 114140.992\n"
     ]
    }
   ],
   "source": [
    "dep_pd_train = train.loc[:, ['departments']]\n",
    "dep_train = np.squeeze(dep_pd_train.as_matrix())\n",
    "\n",
    "n_dep = len(set(dep_train))\n",
    "tri_n_dep = int(n_dep * (n_dep + 1) / 2)\n",
    "\n",
    "# random-effect placeholder\n",
    "dep_data = tf.placeholder(tf.int32, [N])\n",
    "\n",
    "# for unstructure, covariance has degree of freedom of: n_dep * (n_dep + 1) / 2 \n",
    "tril_dep = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([tri_n_dep]))))\n",
    "tril_dep = tfd.fill_triangular(tril_dep)\n",
    "\n",
    "# random normal using lower triangular cholesky\n",
    "alpha_dep = MultivariateNormalTriL(loc=tf.zeros(n_dep), scale_tril=tril_dep)\n",
    "alpha_random_effects = tf.gather(alpha_dep, dep_data)\n",
    "\n",
    "mu_y = alpha + alpha_random_effects + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_dep = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_dep])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_dep])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha,\n",
    "    alpha_dep: q_alpha_dep\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(tf.matmul(tril_dep, tf.transpose(tril_dep))))\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studage' 'service' 'lectage']\n",
      "[ 0.03710853 -0.09770855 -0.07673685]\n",
      "[2.3447003]\n",
      "Zmu= [0.798795   0.80185294 1.0237148  0.96471834 0.9403538  0.88180935\n",
      " 0.99735165 0.9491084  0.9059565  0.7127774  0.7378387  1.060403\n",
      " 0.94155735 1.1663647 ]\n",
      "G= [[ 6.688882   1.6805217  3.196035   3.58497    2.6919034  4.1440687\n",
      "   1.9928014  3.8834078  2.7782745  3.6089501  2.28403    5.2476892\n",
      "   1.4535633  3.9973109]\n",
      " [ 1.6805217  7.147706   6.310958   3.201768   4.298555   3.1748385\n",
      "   3.6305506  6.8168106  3.6901498  5.6891193  1.5032123  7.31422\n",
      "   2.8937173  3.6828547]\n",
      " [ 3.196035   6.310958   7.325194   5.507472   5.4685693  5.3713517\n",
      "   5.671163   8.13764    4.6462884  6.4235187  2.81606    8.426712\n",
      "   3.7307885  5.410662 ]\n",
      " [ 3.58497    3.201768   5.507472  10.535321   6.4953136  8.867864\n",
      "   9.719269   7.7593846  5.289279   5.579581   8.640089   8.583285\n",
      "   6.7578154  8.214806 ]\n",
      " [ 2.6919034  4.298555   5.4685693  6.4953136  5.4250226  6.2072945\n",
      "   6.944583   7.500811   4.7216673  5.6884956  8.058671   7.486223\n",
      "   4.816139   6.0477486]\n",
      " [ 4.1440687  3.1748385  5.3713517  8.867864   6.2072945 12.951958\n",
      "  11.349306  10.221826   7.313305  12.083146  11.47024   11.417972\n",
      "   7.4506984 12.350506 ]\n",
      " [ 1.9928014  3.6305506  5.671163   9.719269   6.944583  11.349306\n",
      "  16.092936  11.629303   9.4813175 12.0675535 18.713688  11.40911\n",
      "   9.660719  12.474035 ]\n",
      " [ 3.8834078  6.8168106  8.13764    7.7593846  7.500811  10.221826\n",
      "  11.629303  15.361151   9.9966955 13.106809  15.979679  15.040062\n",
      "   8.866316  12.24538  ]\n",
      " [ 2.7782745  3.6901498  4.6462884  5.289279   4.7216673  7.313305\n",
      "   9.4813175  9.9966955  7.6884675 10.001323  13.514741  10.202862\n",
      "   7.50783    9.969518 ]\n",
      " [ 3.6089501  5.6891193  6.4235187  5.579581   5.6884956 12.083146\n",
      "  12.0675535 13.106809  10.001323  17.673464  14.680411  14.942701\n",
      "  10.462771  15.674818 ]\n",
      " [ 2.28403    1.5032123  2.81606    8.640089   8.058671  11.47024\n",
      "  18.713688  15.979679  13.514741  14.680411  51.704704  16.232433\n",
      "  17.308123  17.805208 ]\n",
      " [ 5.2476892  7.31422    8.426712   8.583285   7.486223  11.417972\n",
      "  11.40911   15.040062  10.202862  14.942701  16.232433  19.124887\n",
      "  12.332459  15.765992 ]\n",
      " [ 1.4535633  2.8937173  3.7307885  6.7578154  4.816139   7.4506984\n",
      "   9.660719   8.866316   7.50783   10.462771  17.308123  12.332459\n",
      "  14.955175  14.433577 ]\n",
      " [ 3.9973109  3.6828547  5.410662   8.214806   6.0477486 12.350506\n",
      "  12.474035  12.24538    9.969518  15.674818  17.805208  15.765992\n",
      "  14.433577  20.905983 ]]\n"
     ]
    }
   ],
   "source": [
    "# fixed effect estimate\n",
    "q_beta_approx = sess.run(q_beta_fixed_effects)\n",
    "q_alpha_approx = sess.run(q_alpha)\n",
    "q_alpha_dep_approx = sess.run(q_alpha_dep)\n",
    "\n",
    "print(x_pd_train.columns.values)\n",
    "print(q_beta_approx)\n",
    "print(q_alpha_approx)\n",
    "\n",
    "# Z estimate of random effect without fixed effect\n",
    "print('Zmu=', q_alpha_dep_approx)\n",
    "print('G=', sess.run(tf.matmul(tril_dep, tf.transpose(tril_dep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.1324344\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> mixed effects with compound symmetry covariance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init G= [[1.7084634  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 1.7084634  0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 1.7084634  0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 1.7084634  0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 1.7084634  0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 1.7084634\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  1.7084634  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 1.7084634  0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 1.7084634  0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 1.7084634  0.54182154 0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 1.7084634  0.54182154\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 1.7084634\n",
      "  0.54182154 0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  1.7084634  0.54182154]\n",
      " [0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 0.54182154 0.54182154 0.54182154 0.54182154 0.54182154\n",
      "  0.54182154 1.7084634 ]]\n",
      "250/250 [100%] ██████████████████████████████ Elapsed: 12s | Loss: 118309.773\n"
     ]
    }
   ],
   "source": [
    "sigma_B = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))\n",
    "sigma_S = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([]))))\n",
    "dep_cov = tf.ones([n_dep, n_dep])\n",
    "dep_cov = dep_cov * sigma_B + tf.diag(tf.ones([n_dep]) * sigma_S)\n",
    "\n",
    "alpha_dep = MultivariateNormalFullCovariance(loc=tf.zeros(n_dep), covariance_matrix=dep_cov)\n",
    "alpha_random_effects = tf.gather(alpha_dep, dep_data)\n",
    "\n",
    "mu_y = alpha + alpha_random_effects + ed.dot(fixed_effects, beta_fixed_effects)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# approximate random-effect distribution\n",
    "q_alpha_dep = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([n_dep])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([n_dep])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    beta_fixed_effects: q_beta_fixed_effects,\n",
    "    alpha: q_alpha,\n",
    "    alpha_dep: q_alpha_dep\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('init G=', sess.run(dep_cov))\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studage' 'service' 'lectage']\n",
      "[0.13612273 0.20245148 0.10570623]\n",
      "[1.2693185]\n",
      "Zmu= [2.0034733 1.8985199 1.9688336 2.056011  2.0506117 2.0208988 2.1265097\n",
      " 1.9922329 1.7849714 1.5615512 1.7143933 1.9573094 1.7400469 1.9246038]\n",
      "G= [[3.5868363 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5868363 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5868363 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5868363 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5868363 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5868363 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5868363\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5868363 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5868363 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5868363 3.5628698 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5868363 3.5628698 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5868363 3.5628698 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5868363 3.5628698]\n",
      " [3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698\n",
      "  3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5628698 3.5868363]]\n"
     ]
    }
   ],
   "source": [
    "q_beta_approx = sess.run(q_beta_fixed_effects)\n",
    "q_alpha_approx = sess.run(q_alpha)\n",
    "q_alpha_dep_approx = sess.run(q_alpha_dep)\n",
    "\n",
    "print(x_pd_train.columns.values)\n",
    "print(q_beta_approx)\n",
    "print(q_alpha_approx)\n",
    "\n",
    "# Z estimate of random effect without fixed effect\n",
    "print('Zmu=', q_alpha_dep_approx)\n",
    "print('G=', sess.run(dep_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.1234922\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> random coefficients - random intercept & slope model by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [100%] ██████████████████████████████ Elapsed: 27s | Loss: 112163.727\n"
     ]
    }
   ],
   "source": [
    "N, D = x_train.shape\n",
    "dep_pd_train = train.loc[:, ['departments']]\n",
    "dep_train = np.squeeze(dep_pd_train.as_matrix())\n",
    "n_dep = len(set(dep_train))\n",
    "\n",
    "fixed_effects = tf.placeholder(tf.float32, [N, D])\n",
    "dep_data = tf.placeholder(tf.int32, [N])\n",
    "\n",
    "blk_size = D + 1 # alpha + beta for random coeffs\n",
    "cov_size = n_dep * blk_size\n",
    "\n",
    "cov = []\n",
    "\n",
    "tri_n_dep = int(blk_size * (blk_size + 1) / 2)\n",
    "tril_dep = tf.sqrt(tf.exp(tf.Variable(tf.random_normal([tri_n_dep]))))\n",
    "tril_dep = tfd.fill_triangular(tril_dep)\n",
    "x = tf.matmul(tril_dep, tf.transpose(tril_dep))\n",
    "\n",
    "# construct block diagonal covariance matrix\n",
    "for bidx in range(cov_size // blk_size):\n",
    "    row = []    \n",
    "    \n",
    "    for ridx in range(blk_size):\n",
    "        row = []\n",
    "        row.append(tf.zeros([bidx*blk_size]))\n",
    "        row.append(x[ridx, :])\n",
    "        row.append(tf.zeros([cov_size - bidx*blk_size - blk_size]))\n",
    "        cov.append(tf.expand_dims(tf.concat(row, 0), 0))\n",
    "    \n",
    "cov = tf.concat(cov, 0)\n",
    "    \n",
    "ab_dep_rnd_coeff = MultivariateNormalFullCovariance(loc=tf.zeros(cov_size), covariance_matrix=cov)\n",
    "ab_dep_rnd_coeff2 = tf.reshape(ab_dep_rnd_coeff, [-1, blk_size])\n",
    "alpha_random_effects = tf.gather(ab_dep_rnd_coeff2, dep_data)\n",
    "\n",
    "mu_y = alpha_random_effects[:, 0] + tf.reduce_sum(tf.multiply(fixed_effects, alpha_random_effects[:, 1:]), 1)\n",
    "y = Normal(loc=mu_y, scale=tf.ones(N))\n",
    "\n",
    "# latent fixed effects\n",
    "q_ab_dep_rnd_coeff = Normal(\n",
    "    loc=tf.Variable(tf.random_normal([cov_size])),\n",
    "    scale=tf.nn.softplus(tf.Variable(tf.random_normal([cov_size])))\n",
    ")\n",
    "\n",
    "latent_vars = {\n",
    "    ab_dep_rnd_coeff: q_ab_dep_rnd_coeff\n",
    "}\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "inference = ed.KLqp(latent_vars, data={fixed_effects: x_train, dep_data: dep_train, y: y_train})\n",
    "inference.run(n_samples=5, n_iter=250)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance random ab =\n",
      " [array([[8.11938190e+00, 2.54074335e-01, 5.41478992e-01, 8.10897164e-03],\n",
      "       [2.54074335e-01, 2.09429301e-02, 3.20738330e-02, 7.56057154e-04],\n",
      "       [5.41478992e-01, 3.20738330e-02, 1.09296724e-01, 3.16768326e-03],\n",
      "       [8.10897164e-03, 7.56057154e-04, 3.16768326e-03, 7.12331571e-03]],\n",
      "      dtype=float32)]\n",
      "random ab per dep =\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alpha', array(['studage', 'service', 'lectage'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.4660883 , -0.05844691, -0.2054963 , -0.11642824],\n",
       "       [ 2.9375708 ,  0.03732561, -0.11960767, -0.02853017],\n",
       "       [ 2.836221  ,  0.05001316,  0.40148878,  0.02988731],\n",
       "       [ 2.8940868 ,  0.09372124,  0.0169617 , -0.05085459],\n",
       "       [ 3.3264937 ,  0.0368668 ,  0.2341379 , -0.01421959],\n",
       "       [ 2.795564  ,  0.05089311, -0.03981573, -0.05163014],\n",
       "       [ 1.9384717 ,  0.22952229,  0.30392706,  0.07673109],\n",
       "       [ 2.2366908 ,  0.13160513,  0.5279447 ,  0.01156574],\n",
       "       [ 1.598231  ,  0.4462008 ,  0.25450325, -0.02061877],\n",
       "       [ 2.739753  ,  0.09396379,  0.41576257, -0.07260871],\n",
       "       [ 2.752305  ,  0.18410248,  0.21044725, -0.04393198],\n",
       "       [ 2.7042968 , -0.00896681,  0.17553703, -0.0935858 ],\n",
       "       [ 2.369669  ,  0.04597908, -0.18835661,  0.02289018],\n",
       "       [ 2.3525453 ,  0.17976658,  0.47863266, -0.02203353]],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"covariance random ab =\\n\", sess.run([cov[0:blk_size, 0:blk_size]]))\n",
    "print(\"random ab per dep =\\n\")\n",
    "display(['alpha', x_pd_train.columns.values])\n",
    "display(sess.run(tf.reshape(q_ab_dep_rnd_coeff, [-1, blk_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae= 1.144545\n"
     ]
    }
   ],
   "source": [
    "X_feed_dict = {\n",
    "    fixed_effects: x_train,\n",
    "    dep_data: dep_train\n",
    "}\n",
    "\n",
    "y_posterior = ed.copy(y, latent_vars)\n",
    "\n",
    "mae = compute_mean_absolute_error(y_posterior, X_feed_dict, y_train)\n",
    "print('mae=', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
